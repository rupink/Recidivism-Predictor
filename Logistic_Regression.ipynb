{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Train_Test_Loops import *\n",
    "from Imports import *\n",
    "from LogisticRegression import *\n",
    "from Data_Format import *\n",
    "from TrainandTestDataset import * \n",
    "from Main_Adver_Network import *\n",
    "from Train_Advs_Main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "#device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "# format Data\n",
    "Data = Data_Format_1(CONTENTS)\n",
    "# declare train/test dataset\n",
    "trainloader = torch.utils.data.DataLoader(TrainandTestDataset(Data.x_train, Data.y_train), batch_size=32, shuffle = True)\n",
    "testloader = torch.utils.data.DataLoader(TrainandTestDataset(Data.x_test, Data.y_test), batch_size=32, shuffle = False)\n",
    "# declare the model\n",
    "model = LogisticRegression(2, 1)\n",
    "\n",
    "# define the criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# select the optimizer and pass to it the parameters of the model it will optimize\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss= 0.2659081220626831\n",
      "epoch: 20 loss= 0.24835723638534546\n",
      "epoch: 40 loss= 0.21286319196224213\n",
      "epoch: 60 loss= 0.22821196913719177\n",
      "epoch: 80 loss= 0.2455911636352539\n",
      "epoch: 100 loss= 0.20074410736560822\n",
      "epoch: 120 loss= 0.22189898788928986\n",
      "epoch: 140 loss= 0.3147500455379486\n",
      "epoch: 160 loss= 0.22658978402614594\n",
      "epoch: 180 loss= 0.19977842271327972\n",
      "epoch: 200 loss= 0.30858343839645386\n",
      "epoch: 220 loss= 0.26492488384246826\n",
      "epoch: 240 loss= 0.17196102440357208\n",
      "epoch: 260 loss= 0.24187031388282776\n",
      "epoch: 280 loss= 0.23862361907958984\n",
      "epoch: 300 loss= 0.2993795871734619\n",
      "epoch: 320 loss= 0.21080516278743744\n",
      "epoch: 340 loss= 0.25350236892700195\n",
      "epoch: 360 loss= 0.31777265667915344\n",
      "epoch: 380 loss= 0.23223982751369476\n",
      "epoch: 400 loss= 0.24768339097499847\n",
      "epoch: 420 loss= 0.20325274765491486\n",
      "epoch: 440 loss= 0.26523420214653015\n",
      "epoch: 460 loss= 0.2375442087650299\n",
      "epoch: 480 loss= 0.2778908908367157\n",
      "epoch: 500 loss= 0.26147133111953735\n",
      "epoch: 520 loss= 0.28857704997062683\n",
      "epoch: 540 loss= 0.2087555080652237\n",
      "epoch: 560 loss= 0.23361705243587494\n",
      "epoch: 580 loss= 0.233397975564003\n",
      "epoch: 600 loss= 0.27534329891204834\n",
      "epoch: 620 loss= 0.26093971729278564\n",
      "epoch: 640 loss= 0.2519747018814087\n",
      "epoch: 660 loss= 0.24921946227550507\n",
      "epoch: 680 loss= 0.22037464380264282\n",
      "epoch: 700 loss= 0.2027072310447693\n",
      "epoch: 720 loss= 0.22539225220680237\n",
      "epoch: 740 loss= 0.23224535584449768\n",
      "epoch: 760 loss= 0.23271846771240234\n",
      "epoch: 780 loss= 0.269358366727829\n",
      "epoch: 800 loss= 0.2527221143245697\n",
      "epoch: 820 loss= 0.23518003523349762\n",
      "epoch: 840 loss= 0.21650725603103638\n",
      "epoch: 860 loss= 0.22943741083145142\n",
      "epoch: 880 loss= 0.2760390639305115\n",
      "epoch: 900 loss= 0.22291988134384155\n",
      "epoch: 920 loss= 0.22893546521663666\n",
      "epoch: 940 loss= 0.3141035735607147\n",
      "epoch: 960 loss= 0.23338693380355835\n",
      "epoch: 980 loss= 0.18519233167171478\n"
     ]
    }
   ],
   "source": [
    "Training_Loop(model, criterion, optimizer, 1000, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.992103204131126\n"
     ]
    }
   ],
   "source": [
    "Testing_Loop(model, criterion, testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2_pred = model(Data.x_test.float())\n",
    "\n",
    "#get race from data\n",
    "race = CONTENTS[[\"race\"]].copy()\n",
    "\n",
    "#convert race to int type\n",
    "arr = []\n",
    "for i in race[\"race\"]:\n",
    "  if i == \"African-American\":\n",
    "    arr.append(0)\n",
    "  elif i == \"Caucasian\":\n",
    "    arr.append(1)\n",
    "  else:\n",
    "    arr.append(-1)\n",
    "\n",
    "#append to all data\n",
    "race[\"race\"] = arr\n",
    "new_race = torch.tensor(race.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of defendants:  7214\n",
      "number of black defendants in the database:  3696\n",
      "number of white defendants in the database:  2454\n",
      "recidivated black defendants:  51.433982683982684\n",
      "recidivated white defendants:  39.36430317848411\n"
     ]
    }
   ],
   "source": [
    "#Find the total recidivated rates of Caucasian and African-Americans\n",
    "b = 0\n",
    "w = 0\n",
    "br = 0\n",
    "wr = 0\n",
    "\n",
    "for i in range(len(new_race)):\n",
    "  if new_race[i] == 0:\n",
    "    b += 1\n",
    "  if new_race[i] == 1:\n",
    "    w += 1\n",
    "  if new_race[i] == 0 and Data.new_y_axis[i] == 1:\n",
    "    br += 1\n",
    "  if new_race[i] == 1 and Data.new_y_axis[i] == 1:\n",
    "    wr += 1\n",
    "\n",
    "print(\"total number of defendants: \", len(new_race))\n",
    "print(\"number of black defendants in the database: \", b)\n",
    "print(\"number of white defendants in the database: \", w)\n",
    "print(\"recidivated black defendants: \", br/b*100)\n",
    "print(\"recidivated white defendants: \", wr/w*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data based on paper: 80% training and 20% test\n",
    "\n",
    "#find the index at which to split the data\n",
    "val = np.floor(len(new_race)*0.8)\n",
    "\n",
    "#first 80% of the data\n",
    "race_train = new_race[:val.astype(int)]\n",
    "\n",
    "#last 20% of the data\n",
    "race_test = new_race[val.astype(int):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of African-Americans that reoffend and were predicted to reoffend:  214\n",
      "# of African-Americans that did not reoffend and were predicted to not reoffend:  204\n",
      "# of African-Americans that did not reoffend but were predicted to reoffend:  145\n",
      "# of African-Americans that did reoffend but were predicted not to reoffend:  181\n",
      "PPV:  59.610027855153206 %\n",
      "NPV:  52.98701298701298 %\n",
      "False Positive Parity:  41.54727793696275 %\n"
     ]
    }
   ],
   "source": [
    "#Find # of African Americans that are predicted to reoffend vs. who actually reoffend\n",
    "actual = 0 #True Positive\n",
    "were_predicted = 0 #False Positive\n",
    "not_predicted = 0 #True Negative\n",
    "wrong_predict = 0 #False Negative\n",
    "\n",
    "for i in range(len(Data.x_test)):\n",
    "  if race_test[i] == 0: #If African-American\n",
    "    if y2_pred[i] >= 0.5: #If predicted to reoffend\n",
    "      if Data.y_test[i] == 1: #did reoffend\n",
    "        actual +=1\n",
    "      if Data.y_test[i] == 0: #did not reoffend\n",
    "        were_predicted += 1\n",
    "    if y2_pred[i] < 0.5: \n",
    "      if Data.y_test[i] == 0: #did not reoffend \n",
    "        not_predicted += 1\n",
    "      if Data.y_test[i] == 1: #did reoffend\n",
    "        wrong_predict += 1\n",
    "\n",
    "print(\"# of African-Americans that reoffend and were predicted to reoffend: \", actual)\n",
    "print(\"# of African-Americans that did not reoffend and were predicted to not reoffend: \", not_predicted)\n",
    "print(\"# of African-Americans that did not reoffend but were predicted to reoffend: \", were_predicted)\n",
    "print(\"# of African-Americans that did reoffend but were predicted not to reoffend: \", wrong_predict)\n",
    "print(\"PPV: \", actual/(actual + were_predicted)*100, \"%\")\n",
    "print(\"NPV: \", not_predicted/(not_predicted + wrong_predict)*100, \"%\")\n",
    "print(\"False Positive Parity: \", were_predicted/(were_predicted + not_predicted)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Caucasians that reoffend and were predicted to reoffend:  78\n",
      "# of Caucasians that did not reoffend and were predicted to not reoffend:  220\n",
      "# of Caucasians that did not reoffend but were predicted to reoffend:  78\n",
      "# of Caucasians that did reoffend but were predicted not to reoffend:  100\n",
      "PPV:  50.0 %\n",
      "NPV:  68.75 %\n",
      "False Positive Parity:  26.174496644295303 %\n"
     ]
    }
   ],
   "source": [
    "#Find # of Caucasian Americans that are predicted to reoffend vs. who actually reoffend\n",
    "actual = 0 #True Positive\n",
    "were_predicted = 0 #False Positive\n",
    "not_predicted = 0 #True Negative\n",
    "wrong_predict = 0 #False Negative\n",
    "\n",
    "for i in range(len(Data.x_test)):\n",
    "  if race_test[i] == 1: #If Caucasian\n",
    "    if y2_pred[i] >= 0.5: #If predicted to reoffend\n",
    "      if Data.y_test[i] == 1: #did reoffend\n",
    "        actual +=1\n",
    "      if Data.y_test[i] == 0: #did not reoffend\n",
    "        were_predicted += 1\n",
    "    if y2_pred[i] < 0.5: \n",
    "      if Data.y_test[i] == 0: #did not reoffend \n",
    "        not_predicted += 1\n",
    "      if Data.y_test[i] == 1: #did reoffend\n",
    "        wrong_predict += 1\n",
    "\n",
    "print(\"# of Caucasians that reoffend and were predicted to reoffend: \", actual)\n",
    "print(\"# of Caucasians that did not reoffend and were predicted to not reoffend: \", not_predicted)\n",
    "print(\"# of Caucasians that did not reoffend but were predicted to reoffend: \", were_predicted)\n",
    "print(\"# of Caucasians that did reoffend but were predicted not to reoffend: \", wrong_predict)\n",
    "print(\"PPV: \", actual/(actual + were_predicted)*100, \"%\")\n",
    "print(\"NPV: \", not_predicted/(not_predicted + wrong_predict)*100, \"%\")\n",
    "print(\"False Positive Parity: \", were_predicted/(were_predicted + not_predicted)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of African-Americans that reoffend:  21\n",
      "# of African-Americans that did not reoffend:  342\n",
      "# of African-Americans that did not reoffend but were predicted to reoffend:  7\n",
      "# of African-Americans that did reoffend but were predicted not to reoffend:  374\n",
      "PPV:  75.0 %\n",
      "NPV:  47.76536312849162 %\n",
      "False Positive Parity:  2.005730659025788 %\n"
     ]
    }
   ],
   "source": [
    "#adjusting thresholds: use 60%\n",
    "\n",
    "#Find # of African Americans that are predicted to reoffend vs. who actually reoffend\n",
    "actual = 0 #True Positive\n",
    "were_predicted = 0 #False Positive\n",
    "not_predicted = 0 #True Negative\n",
    "wrong_predict = 0 #False Negative\n",
    "\n",
    "for i in range(len(Data.x_test)):\n",
    "  if race_test[i] == 0: #If African-American\n",
    "    if y2_pred[i] >= 0.6: #If predicted to reoffend\n",
    "      if Data.y_test[i] == 1: #did reoffend\n",
    "        actual +=1\n",
    "      elif Data.y_test[i] == 0: #did not reoffend\n",
    "        were_predicted += 1\n",
    "    elif y2_pred[i] < 0.6: \n",
    "      if Data.y_test[i] == 0: #did not reoffend \n",
    "        not_predicted += 1\n",
    "      if Data.y_test[i] == 1: #did reoffend\n",
    "        wrong_predict += 1\n",
    "\n",
    "print(\"# of African-Americans that reoffend: \", actual)\n",
    "print(\"# of African-Americans that did not reoffend: \", not_predicted)\n",
    "print(\"# of African-Americans that did not reoffend but were predicted to reoffend: \", were_predicted)\n",
    "print(\"# of African-Americans that did reoffend but were predicted not to reoffend: \", wrong_predict)\n",
    "print(\"PPV: \", actual/(actual + were_predicted)*100, \"%\")\n",
    "print(\"NPV: \", not_predicted/(not_predicted + wrong_predict)*100, \"%\")\n",
    "print(\"False Positive Parity: \", were_predicted/(were_predicted + not_predicted)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Caucasians that reoffend:  6\n",
      "# of Caucasians that did not reoffend:  293\n",
      "# of Caucasians that did not reoffend but were predicted to reoffend:  5\n",
      "# of Caucasians that did reoffend but were predicted not to reoffend:  172\n",
      "PPV:  54.54545454545454 %\n",
      "NPV:  63.01075268817205 %\n",
      "False Positive Parity:  1.6778523489932886 %\n"
     ]
    }
   ],
   "source": [
    "#adjusting thresholds: use 60%\n",
    "\n",
    "#Find # of Caucasian Americans that are predicted to reoffend vs. who actually reoffend\n",
    "actual = 0 #True Positive\n",
    "were_predicted = 0 #False Positive\n",
    "not_predicted = 0 #True Negative\n",
    "wrong_predict = 0 #False Negative\n",
    "\n",
    "for i in range(len(Data.x_test)):\n",
    "  if race_test[i] == 1: #If Caucasian\n",
    "    if y2_pred[i] >= 0.6: #If predicted to reoffend\n",
    "      if Data.y_test[i] == 1: #did reoffend\n",
    "        actual +=1\n",
    "      elif Data.y_test[i] == 0: #did not reoffend\n",
    "        were_predicted += 1\n",
    "    elif y2_pred[i] < 0.6: \n",
    "      if Data.y_test[i] == 0: #did not reoffend \n",
    "        not_predicted += 1\n",
    "      if Data.y_test[i] == 1: #did reoffend\n",
    "        wrong_predict += 1\n",
    "\n",
    "print(\"# of Caucasians that reoffend: \", actual)\n",
    "print(\"# of Caucasians that did not reoffend: \", not_predicted)\n",
    "print(\"# of Caucasians that did not reoffend but were predicted to reoffend: \", were_predicted)\n",
    "print(\"# of Caucasians that did reoffend but were predicted not to reoffend: \", wrong_predict)\n",
    "print(\"PPV: \", actual/(actual + were_predicted)*100, \"%\")\n",
    "print(\"NPV: \", not_predicted/(not_predicted + wrong_predict)*100, \"%\")\n",
    "print(\"False Positive Parity: \", were_predicted/(were_predicted + not_predicted)*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
